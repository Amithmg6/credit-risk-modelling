{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10ec5d58",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b849cb48",
   "metadata": {},
   "source": [
    "A complete project for credit risk modeling, demonstrating hyperparameter tuning and conceptual deployment in the financial domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5517395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To install: pip install scikit-learn numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf52032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f501637",
   "metadata": {},
   "source": [
    "## Business Problem Statement:\n",
    "\n",
    "An online lender wants to automate its loan approval process. The goal is to build a predictive model that assesses the credit risk of new applicants. A low-risk applicant should be approved, while a high-risk applicant should be rejected to minimize financial losses for the lender. This is a classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c35f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2. Simulate a Realistic-Looking Dataset\n",
    "# # We'll create a synthetic dataset that mimics loan application data.\n",
    "\n",
    "# print(\"Simulating a dataset for credit risk modeling...\")\n",
    "# np.random.seed(42)\n",
    "# num_applicants = 5000\n",
    "# data = {\n",
    "#     'credit_score': np.random.normal(700, 50, num_applicants).astype(int),\n",
    "#     'annual_income': np.random.lognormal(mean=11, sigma=0.8, size=num_applicants).astype(int),\n",
    "#     'loan_amount': np.random.normal(25000, 10000, num_applicants).astype(int),\n",
    "#     'loan_term_years': np.random.choice([2, 3, 4, 5], size=num_applicants),\n",
    "#     # The target variable (0 = No Default, 1 = Default)\n",
    "#     'risk_label': np.random.choice([0, 1], size=num_applicants, p=[0.9, 0.1])\n",
    "# }\n",
    "# df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "493d504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"credit_risk_modelling_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58b9d792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype\n",
      "---  ------           --------------  -----\n",
      " 0   credit_score     5000 non-null   int64\n",
      " 1   annual_income    5000 non-null   int64\n",
      " 2   loan_amount      5000 non-null   int64\n",
      " 3   loan_term_years  5000 non-null   int64\n",
      " 4   risk_label       5000 non-null   int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 195.4 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d271199c",
   "metadata": {},
   "source": [
    "#### Conditions to add risk label. This can be modified for different policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7757ace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's add a simple correlation: lower credit score and higher loan amount increase risk\n",
    "df.loc[df['credit_score'] < 650, 'risk_label'] = 1\n",
    "df.loc[df['loan_amount'] > 40000, 'risk_label'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a10a0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. Training data shape: (4000, 4)\n",
      "Test data shape: (1000, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Features (X) and Target (y)\n",
    "X = df[['credit_score', 'annual_income', 'loan_amount', 'loan_term_years']]\n",
    "y = df['risk_label']\n",
    "\n",
    "# Split the data into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Dataset loaded. Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baa6eb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Define the Model and the Hyperparameter Grid\n",
    "# We will use the Gradient Boosting Classifier, a powerful model for this task.\n",
    "model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid to search over.\n",
    "# Grid Search will explore all combinations of these parameters.\n",
    "# The 'verbose' argument in GridSearchCV will show us the progress.\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],          # Number of boosting stages\n",
    "    'learning_rate': [0.01, 0.05, 0.1],        # Step size shrinkage\n",
    "    'max_depth': [3, 5, 7],                   # Maximum depth of the individual regression estimators\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee7b9d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Grid Search for hyperparameter tuning...\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "\n",
      "Grid Search finished.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. Instantiate and Run Grid Search\n",
    "print(\"\\nStarting Grid Search for hyperparameter tuning...\")\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',   # We want to maximize accuracy\n",
    "    cv=5,                 # Perform 5-fold cross-validation\n",
    "    n_jobs=-1,            # Use all available CPU cores\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"\\nGrid Search finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d3ba53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best hyperparameters found:\n",
      "{'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. Get and Evaluate the Best Model\n",
    "print(\"\\nBest hyperparameters found:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccc29996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of the best model on the test set: 0.9140\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  No Default       0.89      1.00      0.94       694\n",
      "     Default       1.00      0.72      0.84       306\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.94      0.86      0.89      1000\n",
      "weighted avg       0.92      0.91      0.91      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions on the unseen test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate and print the performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=['No Default', 'Default'])\n",
    "\n",
    "print(f\"\\nAccuracy of the best model on the test set: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dd4fc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Conceptual Deployment ---\n",
      "Saving the best model to 'credit_risk_model.joblib'...\n",
      "Model successfully saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6. Conceptual Deployment\n",
    "# In a real-world scenario, the trained 'best_model' would be saved to a file.\n",
    "# This file would then be used by a production application or API to make\n",
    "# real-time predictions on new data.\n",
    "print(\"\\n--- Conceptual Deployment ---\")\n",
    "\n",
    "# Save the final, optimized model to a file using joblib.\n",
    "model_filename = 'credit_risk_model.joblib'\n",
    "print(f\"Saving the best model to '{model_filename}'...\")\n",
    "joblib.dump(best_model, model_filename)\n",
    "print(\"Model successfully saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77070a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully for real-time predictions.\n",
      "\n",
      "Assessing a new applicant...\n",
      "Applicant Data: {'credit_score': 700, 'annual_income': 75000, 'loan_amount': 30000, 'loan_term_years': 3}\n",
      "Prediction: Low Risk: Approve Loan\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Conceptual API Usage:\n",
    "# In a separate file (e.g., 'api_server.py'), you would set up a simple API\n",
    "# that loads the model and takes a new applicant's data as input.\n",
    "# Example of how you would load and use the model in a live application:\n",
    "\n",
    "try:\n",
    "    loaded_model = joblib.load('credit_risk_model.joblib')\n",
    "    print(\"Model loaded successfully for real-time predictions.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Model file not found. Please train and save the model first.\")\n",
    "\n",
    "def assess_credit_risk(applicant_data):\n",
    "    # The applicant_data would be a dictionary from an API request, e.g.:\n",
    "    # {'credit_score': 720, 'annual_income': 85000, 'loan_amount': 20000, 'loan_term_years': 4}\n",
    "    \n",
    "    # Convert the new data to a format the model expects (a DataFrame or 2D array)\n",
    "    df_new = pd.DataFrame([applicant_data])\n",
    "    \n",
    "    # Make the prediction\n",
    "    prediction = loaded_model.predict(df_new)\n",
    "    \n",
    "    # The prediction is 0 for 'No Default' and 1 for 'Default'\n",
    "    if prediction[0] == 0:\n",
    "        return \"Low Risk: Approve Loan\"\n",
    "    else:\n",
    "        return \"High Risk: Reject Loan\"\n",
    "\n",
    "# To test this function, you could call it with a new data point:\n",
    "new_applicant = {'credit_score': 700, 'annual_income': 75000, 'loan_amount': 30000, 'loan_term_years': 3}\n",
    "print(\"\\nAssessing a new applicant...\")\n",
    "print(f\"Applicant Data: {new_applicant}\")\n",
    "# For this example, we'll just show the concept, not run it.\n",
    "prediction = assess_credit_risk(new_applicant)\n",
    "print(f\"Prediction: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665bc496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17eed40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c794bac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
